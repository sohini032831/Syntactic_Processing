{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ae645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences with universal tagset\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e913b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First three sentences in te dataset\n",
    "nltk_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the random seed\n",
    "random.seed(1234)\n",
    "\n",
    "#Divide the data into training and test sets\n",
    "train_set, test_set = train_test_split(nltk_data,train_size=0.95)\n",
    "\n",
    "#Get the length of training and test sets\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38acb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of tagged words in training set\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "#Get the length of the total tagged words in training set\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8722cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 10 tokens/words in the training set\n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total unique words in the training set\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of pos tags in the training corpus\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "print(len(T))\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy array of no of pos tags by total vocabulary\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18167d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6447370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeacf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t (pos tags x pos tags)transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of tags matrix\n",
    "# T(i, j) indicates P(tag j given tag i)\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent tags\n",
    "# filter the df to get P(t2, t1) > 0.5\n",
    "tags_frequent = tags_df[tags_df>0.5]\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_frequent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b66948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total length of tagged words in training corpus\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0399626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "\n",
    "# list of tagged words in test set\n",
    "test_run_base = [tup for sent in test_set for tup in sent]\n",
    "\n",
    "# list of  words which are untagged in test set\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a41c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print total time taken to train the algorithm\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced206c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy of model\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the text file\n",
    "lines=[]\n",
    "f = codecs.open(\"Test_sentences.txt\", encoding='utf-8')\n",
    "for line in f:\n",
    "    print(line)\n",
    "    lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfbcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip the special characters and empty strings in the list file\n",
    "test_lines =[sent.rstrip() for sent in lines if sent.rstrip()!='']\n",
    "test_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b901d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the words in the test set which are incorrectly classified\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7172fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the predictions on the test sentences\n",
    "sample_pred_list =[]\n",
    "for line in test_lines:\n",
    "    sample_pred_list=sample_pred_list+list(Viterbi(word_tokenize(line)))\n",
    "sample_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f16db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the tokens in the test file\n",
    "sample_words=[tokens for line in test_lines for tokens in word_tokenize(line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of words which are present in test lines but not in the training corpus\n",
    "words_not_in_corpus = list(set(sample_words) - set(tokens))\n",
    "words_not_in_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the tags predicted for unknown words\n",
    "[tup for tup in sample_pred_list for word in words_not_in_corpus if tup[0]==word ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc38cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us see the count of all tags in the training set\n",
    "from collections import Counter\n",
    "tag_counts = Counter(pair[1] for pair in train_tagged_words)\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5003c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see most common tags can in the training corpus\n",
    "tag_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1329912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see count of incorrectly classfied words for each tag\n",
    "wrong_tag_counts = Counter(pair[1][0][1] for pair in incorrect_tagged_cases)\n",
    "wrong_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see the percentage of verbs which are classifed as 'verb which end with 'ed'\n",
    "verbs = [pair for pair in train_tagged_words if pair[1]=='VERB']\n",
    "ed_verbs = [pair for pair in verbs if pair[0].endswith('ed')]\n",
    "print(len(ed_verbs) / len(verbs))\n",
    "ed_verbs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see the percentage of verbs which are classifed as 'verb which end with 'ing'\n",
    "verbs = [pair for pair in train_tagged_words if pair[1]=='VERB']\n",
    "ing_verbs = [pair for pair in verbs if pair[0].endswith('ing')]\n",
    "print(len(ing_verbs) / len(verbs))\n",
    "ing_verbs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5233220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see percentage of Adjective tags followed by nouns\n",
    "# create a list of all tags (without the words)\n",
    "tags = [pair[1] for pair in train_tagged_words]\n",
    "\n",
    "# create a list of Adj tags\n",
    "adj_tags = [t for t in tags if t == 'ADJ']\n",
    "\n",
    "# create a list of (ADJ, Noun) tags\n",
    "adj_noun_tags = [(t, tags[index+1]) for index, t in enumerate(tags) \n",
    "              if t=='ADJ' and tags[index+1]=='NOUN']\n",
    "\n",
    "print(len(adj_tags))\n",
    "print(len(adj_noun_tags))\n",
    "print(len(adj_noun_tags) / len(adj_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see percentage of Determinent tags followed by nouns\n",
    "dt_tags = [t for t in tags if t == 'DET']\n",
    "dt_noun_tags = [(t, tags[index+1]) for index, t in enumerate(tags) \n",
    "              if t=='DET' and tags[index+1]=='NOUN']\n",
    "\n",
    "print(len(dt_tags))\n",
    "print(len(dt_noun_tags))\n",
    "print(len(dt_noun_tags) / len(dt_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see percentage of Adverbs tags followed by Verbs\n",
    "adv_tags = [t for t in tags if t == 'ADV']\n",
    "adv_vb_tags = [(t, tags[index+1]) for index, t in enumerate(tags) \n",
    "              if t=='ADV' and tags[index+1]=='VERB']\n",
    "\n",
    "print(len(adv_tags))\n",
    "print(len(adv_vb_tags))\n",
    "print(len(adv_vb_tags) / len(adv_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense verbs\n",
    "    (r'.*es$', 'VERB'),               # singular present verbs\n",
    "    (r'.*ould$', 'VERB'),              # modal verbs\n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),   # articles or determinants\n",
    "    (r'.*able$', 'ADJ'),                # adjectives\n",
    "    (r'.*ness$', 'NOUN'),                # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                  # adverbs\n",
    "    (r'.*', 'NOUN')                    # nouns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "# lexicon backed up by the rule-based tagger\n",
    "lexicon_tagger = nltk.UnigramTagger(train_set, backoff=rule_based_tagger)\n",
    "\n",
    "lexicon_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95615655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trigram tagger backed by Bigram backed by Unigram which is backed by rule based tagger\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_set, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_set, backoff=t1)\n",
    "t3 = nltk.TrigramTagger(train_set, backoff=t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0009236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for brill\n",
    "import nltk.tag\n",
    "from nltk.tag import brill\n",
    "from nltk.tag.brill import *\n",
    "from nltk.tbl.template import Template\n",
    "from nltk.tag import BrillTaggerTrainer\n",
    "\n",
    "#Clear existing templates if any\n",
    "Template._cleartemplates()\n",
    "\n",
    "#Load the fntbl37 template\n",
    "templates = fntbl37()\n",
    " \n",
    "#Train the Brill model\n",
    "trainer = BrillTaggerTrainer(t3, templates)\n",
    "brill_tagger = trainer.train(train_set, max_rules=100, min_score=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_updated(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "       \n",
    "        #Check if state probability is zero\n",
    "        if(pmax==0.0):\n",
    "            #If state probability is zero i.e if the word is unknown if updates the tag based on the brill tagger\n",
    "            state_max = brill_tagger.tag([word])[0][1]\n",
    "        else:\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c66b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences with the updated Viterbi algorithm\n",
    "start = time.time()\n",
    "updated_tagged_seq = Viterbi_updated(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "#Print total time taken to train the algorithm\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy for the updated Viterbi algorithm\n",
    "check = [i for i, j in zip(updated_tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(updated_tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us print the test lines with the initial Viterbi algorithm\n",
    "for line in test_lines:\n",
    "    print(list(Viterbi(word_tokenize(line))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us print the test lines with the updated Viterbi algorithm\n",
    "for line in test_lines:\n",
    "    print(list(Viterbi_updated(word_tokenize(line))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70966a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_updated2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "       \n",
    "        #Check if state probability is zero\n",
    "        if(pmax<0.001):\n",
    "            #If state probability is zero i.e if the word is unknown if updates the tag based on the brill tagger\n",
    "            state_max = brill_tagger.tag([word])[0][1]\n",
    "        else:\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff455eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences with the updated Viterbi algorithm\n",
    "start = time.time()\n",
    "updated_tagged_seq = Viterbi_updated2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "#Print total time taken to train the algorithm\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66247890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy for the updated Viterbi algorithm\n",
    "check = [i for i, j in zip(updated_tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(updated_tagged_seq)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
